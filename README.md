# A Time-Distributed CNN-LSTM with Attention Model for Speech Based Emotion Recognition
This model, trained on RAVDESS dataset, aims to accurately predict human emotions through audio.
Model consists of 3 2D CNN blocks, followed by an LSTM-Attention architecture. The model takes chunked Mel spectrograms as input.
This model achieves 84% test accuracy. (Model weights are shared too)
